•	1.5x speed 
•	Turn on subtitles
•	Watch first
•	Watch again but take notes, like summarize or bullet list stuff in the video
•	take a break when timer expires

Module 5 – Lambda, APIs, API Gateway, Containers, Step Functions, Fargate and ECS

https://cgp-oex.wgu.edu/courses/course-v1:WGUx+OEX0032+v01/courseware/04c9f97860cb4a2abb91f13af016e906/9396d5a9a12745669810a6ccffabbf43/2?activate_block_id=block-v1%3AWGUx%2BOEX0032%2Bv01%2Btype%40vertical%2Bblock%405cdc1d7661f544c08441f37f21b8b4da

---------------------------------------------------------------------------------------------------------------
•	"Computing (Containers and Serverless)" (new tab) (1:46)
---------------------------------------------------------------------------------------------------------------
This is just an overview in the pdf restating the topics
---------------------------------------------------------------------------------------------------------------
•	"AWS Lambda" (new tab) (9:24)
---------------------------------------------------------------------------------------------------------------
Lambda is a SaaS product yeah you don’t need to patch (add runtimes etc) it or nothing just throw code at it and pay the bill! – Again “Lambda allows code to run without provisioning (provoking) or managing servers” – provoking was misspelled in M$ word so I kept it
Grr again there are compute options that are VMs and Container services like ECS (ITS IN THE DAMN NAME), however there is a third approach that is called serverless computing (SaaS)
Lambda runs your code in a virtual private cloud (VPC) by default You can also optionally configure AWS Lambda to access resources behind your own VPC. This option allows you to use custom security groups and network access control lists
You choose the amount of memory you want to allocate to your functions. Lambda allocates proportional CPU power, network bandwidth, and disk I/O
Lambda Layers
You can configure your Lambda function to pull in additional code and content in the form of layer. A layer is zip archive containing libraries, custom runtimes or other dependencies. With layers, you can use libraries in your function without needing to include them in your deployment package. 
A function can use up to five layers at a time. The total unzipped size of the function and all layers cannot exceed the unzipped deployment package size limit of 250 MB. Layers let you keep your deployment package small, which makes development easier.
Layers are extracted to the /opt directory in the function runtime environment.
To add layers to a function, developers use the update-function-configuration command.
Maximum memory allocation for a single Lambda function is 3 GB.
The maximum runtime for a Lambda function is 15 minutes.
---------------------------------------------------------------------------------------------------------------
•	"APIs and REST" (new tab) (7:18)
---------------------------------------------------------------------------------------------------------------
APIs make computer software accessible to developers via code.
HTTP status codes:
100s – Informational
200s – Success
300s - Redirection
400s - Client errors
500s - Server errors
HTTP status codes will be included in REST ASPI responses 
Commonly seen HTTP status codes
200 - “200 success” - Indicates success both request was received and accepted by the server 
401 - “401 Unauthorized” - Indicates a client error, Unauthorized, Authentication is required but the provided credentials were not accepted or perhaps no credentials were provided in the request.
403 - “403 Forbidden” - Indicates a client error, Forbidden. The request was properly made, but the server is not allowing the request. 
404 - “404 not found” - Indicates a client error, Not Found. The resource is unavailable or could not be accessed. 
500 -“500 Unspecified” - Indicates an unspecific internal server error. 
503 - “503 unavailable” - Indicates the service is temporarily unavailable 
---------------------------------------------------------------------------------------------------------------
•	"Amazon API Gateway" (new tab) (4:57)
---------------------------------------------------------------------------------------------------------------
API Gateway handles all the tasks that are involved in accepting and processing concurrent API calls at scale. Tasks include traffic management, authorization and access control, monitoring, and API version management.
You can use Amazon API Gateway to build an API.
As your applications evolve and grow, your APIs will proliferate. Because of that, it is important to monitor and manage your APIs.
API interfaces that you develop have a frontend and a backend. The frontend is used by the client applications to make requests. The parts of the API implementation that communicate with the other services is referred to as the backend.
The frontend is encapsulated by method requests and method responses.
The backend is encapsulated by requests and responses that integrate with the other services.
Like most services you pay for only for what you use in this case its calls made to an API and data transferred out.
API Gateway integrates with AWS Lambda so that you can create completely serverless APIs.
When paired with CloudFront it allows you to take advantage of the network of edge locations that provide your users with the lowest latency for API requests and responses.
You can also simultaneously run multiple versions of the same API, which allows you to quickly iterate, test, and release new versions.
IAM can be setup to authorize access to your APIs
If you use OAuth tokens or other authorization mechanisms, Amazon API Gateway can use AWS Lambda to run a Lambda authorizer to help you verify incoming requests.
API gateway works tightly with Lambda so you can create serverless APIs
First, you create REST APIs with Amazon API Gateway. Then, your mobile and web applications can use these APIs to call publicly available AWS services through the code that that you run in AWS Lambda.
Amazon Cognito provides user management and authentication functions to secure the backend API.
---------------------------------------------------------------------------------------------------------------
•	"Containers on AWS" (new tab) (10:18)
---------------------------------------------------------------------------------------------------------------
WHAT THIS FOR EXTRA INFO https://www.youtube.com/watch?v=lef1qR7C_GE
Containers virtualize an operating system
Containers share a virtualized operating system and run as resource-isolated processes.
Containers hold everything that the software needs to run, such as libraries, system tools, code, and the   runtime.
Containers provide process isolation
Containers are isolated from each other, so you do not have to worry about libraries or dependencies being in sync for each service.
Containers allow you to track versions of your application code and their dependencies.
Like VM sprawl Container sprawl occurs when the number of containers in your infrastructure grows significantly and container distribution is not being properly managed.
Another issue is keeping track of the version differences of a container.
Using ECR repository in your task definitions allows you to attach the “AmazonEC2ContainerServiceforEC2Role” to your instances. This allows Amazon EC2 to retrieve the appropriate images for the applications that are managed using Amazon ECR repositories where owners and version control is kept.
Challenges of container management: 
Bin packaging – when there is limited space available on the hosts where containers can run.
Zombie containers is when you run containers that are no longer needed. 
A Zombie containers is a Docker container that refuses to stop when issued a command.
Zombie containers refuse to stop as it cannot process the INIT command to stop gracefully.
You can work around zombie containers in ECS by using the “initProcessEnabled” flag as “PID 1” in the container as a task definition. Doing this allows for a graceful exit of all containers.
Disappearing containers is the issue of having containers that you need — but are no longer running
ECS
ECS – is a container management service that supports Docker it also allows you to run applications on a managed cluster of Amazon EC2 instances.
Amazon ECS has a built – in scheduler (for flexible scheduling) or use a third - party scheduler, Apache Mesos. You can also perform task, service, or daemon scheduling.
ECS APIs s make it straightforward to integrate third - party solutions
ECS launches your containers in your own Amazon VPC (not sure why it wouldn’t) and thus allows you to use your VPC security groups. 
No compute is shared with other customers (Bill Murry “which is nice”)
ECS tasks are defined through JSON templates called “tasks definitions” where you specify one or more containers that are required for your task like the Docker repo and image, Memory and CPU requirements, shared data volumes, and how the containers are linked to each other.
Launch as many tasks as you want from a single task definition, which you register with the service.
---------------------------------------------------------------------------------------------------------------
•	"Amazon Fargate and Amazon Elastic Container Service" (new tab) (13:03)
---------------------------------------------------------------------------------------------------------------
Fargate is a technology for Amazon ECS that allows you to run containers without having to manage servers or clusters.
ECS can use containers provisioned by Fargate to scale, load balance, and manage scheduling of your containers for availability
All Amazon ECS clusters are heterogeneous – you can run both Fargate and Amazon ECS tasks in the same cluster.
Fargate capabilities are available natively in Amazon ECS you don’t need to learn new API actions to run containers on Fargate.
Fargate comes in 50 different combinations of CPU and memory.
Pricing for CPU and memory is charged on a per-second basic with a 1 minute minimum
Fargate and ECS stack
Nice benefit is when a new version of Docker is released with Fargate, upgrades are taken care of for you. BECAUSE IT’S SERVERLESS!!!!
ECS has two modes:
“EC2 launch type” and “Fargate launch type”
With Fargate launch type you only have to package your application in containers then define CPU and memory, network, and IAM policies then launch the application. Fargate is the serverless way to host your Amazon ECS workloads.
(Not mentioned in the WGU doc, I looked it up) - EC2 launch type is used to run your containerized applications on EC2 instances that you register to your Amazon ECS cluster and manage yourself.
Running containers as Fargate is a launch type decision, no need for additional plugins to add to containers
RECAP FIRST:
Fargate – serverless

EC2 - run your containerized applications on Amazon EC2 instances that you register to your Amazon ECS cluster and manage yourself.
Ok this is confusing:
When to use Fargate over EC2
Use EC2 when: 
•	Using Spot or reserved instances 
•	Ruining windows clusters 
•	Needing granular control for compliance
•	Requiring specialized hardware 
Use Fargate when:
•	Running containers without managing a fleet of EC2 instances
•	Needing a quick start for a new app
•	Porting a monolithic app
•	Dealing with highly variable workloads
Again Fargate is serverless no need to provision stuff to run containers
If you want to get an app up and running quickly run Fargate, write a definition, and choose Fargate then your good to go
For a monolithic app by containerizing the app then launching with Fargate, you can worry less about the cluster and focus on the app itself.
If an app you need to deploy needs horizontal scalability e.g. unpredictable in the resources it will need then Fargate is the way to go
If you are a heavy user of EC2 Spot or have reserved instances use EC2 for ECS tasks because there is no way to translate this to spot or reserved in Fargate
If your running M$ windows containers ECS mode is still the best mode because this is not currently supported in Fargate 
If you need granular control of your EC2 instances due to support compliance, governance requirements, broader customization options or specialized hardware you will need to stick with EC2
Kubernetes
Kubernetes open source container orchestration software that allows you to run any type of containerized application by using the same toolset on-premises
Containers are run in logical groupings called pods and you can run and scale one or many containers together as a pod.
Kubernetes control plane software decides when and where to run your pods, traffic routing, and scales your pods based on utilization or other metrics that you define.
Each pod is given an IP address and a single DNS name, which Kubernetes uses to connect your services with each other and external traffic.
Kubernetes lets you define complex containerized applications and run them at scale across a cluster of servers.
Adding new functionality to Kubernetes is easy (its open source)
EKS (Elastic container service)
Kubernetes management runs across multiple Availability zones 
ECR (Container registry)
A fully managed Docker container registry integrated with Amazon ECS. Specify the Amazon ECR repository in your task definition, and Amazon ECS will retrieve the appropriate images for your applications
ECR supports Docker Registry HTTP API version 2(NOT SURE WHAT THE CRAP THIS MEANS) SO YOU CAN interact with ECR using THE Docker CLI commands 
ECR stores your container images in S3
Namespaces allows you to organize your repositories based on your team’s existing workflows
ECR uses IAM for access control
You can transfer your container images to and from Amazon ECS via HTTPS and encrypts data at rest on S3
ECR also supports Third -party integrations
A single application can span multiple containers (interesting…)
Kubernetes is an open source container orchestration software that allows you to deploy and manage containerized applications at scale.
Step Functions 
Step Functions allow the ability to coordinate services into serverless workflows
Workflows are a series of steps
Output of one step is input of the next like Step Functions enables Lambda and ECS to work together
This allows you write less code
You coordinate individual tasks by expressing your workflow as a state machine.
Individual states make decisions based on their input, perform actions, and pass their output to other states
States can perform different functions, For example, they can do some work (perform a task). Or, they can make a choice about which branch in the workflow to continue on.
Tasks are configured to invoke code that is hosted in a function, container, or instance, which can then be run as many times as needed for a period of 1 year.
---------------------------------------------------------------------------------------------------------------
•	"Module Wrap-Up" (new tab) (1:46)
---------------------------------------------------------------------------------------------------------------

Complete the Module 5 knowledge check 
•	These AWS services can increase the ease of running and managing Docker containers:
Elastic container services (ECS), Elastic Kubernetes service (EKS) and Fargate
EKS is a cloud-based container management service that natively integrates with Kubernetes to deploy applications
•	AWS Lambda automatically scales to support incoming requests without the need for additional configuration, and it remains fault-tolerant
•	Tasks perform the work (when configured) in a workflow when using AWS Step Functions
•	A customer should select Amazon Elastic Container Registry (Amazon ECR) if they need to store, manage and deploy Docker container images, with considerations for encryption, third party integrations, and High-Availability 
•	AWS Fargate provides a managed service for running containers
•	Trucking company benefits of containers: 
•	Amazon S3 server-side encryption provides encryption for data at rest for Elastic Container registry (ECR)
•	Amazon Elastic Container registry (ECR) uses defined polices with AWS Identify and access management (IAM) to control who has access to container images
•	Amazon Elastic container service for Kubernetes (Amazon EKS) will deploy a cluster’s worker nodes across multiple availability zones so that a single point of failure can be eliminated 
umm whats the difference between Amazon Elastic container service for Kubernetes and Kubernetes services (are these the same thing?)
•	_ _ and _ describes how Kubernetes works? (might take several tries to determine these as the answer is not given)

